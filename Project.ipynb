{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5d576a8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to C:\\Users\\Windows\n",
      "[nltk_data]     11\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Import Libraries\n",
    "import spacy\n",
    "import re\n",
    "import os\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "\n",
    "# Download required NLTK data\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Load spaCy English model\n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1d7e5743",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Define File Paths\n",
    "# ==========================================\n",
    "DATA_PATH = \"data\"\n",
    "resume_file = os.path.join(DATA_PATH, \"sample_resume.txt\")\n",
    "jd_file = os.path.join(DATA_PATH, \"job_description.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8695c741",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Text Preprocessing Function\n",
    "# ==========================================\n",
    "def clean_text(text):\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text)  # remove punctuation/numbers\n",
    "    text = text.lower()\n",
    "    tokens = [word for word in text.split() if word not in stopwords.words('english')]\n",
    "    return ' '.join(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fb46376a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: NLP Processing and Extraction\n",
    "# ==========================================\n",
    "def extract_entities(text):\n",
    "    doc = nlp(text)\n",
    "    entities = {\"PERSON\": [], \"ORG\": [], \"EDUCATION\": [], \"SKILLS\": [], \"EXPERIENCE\": []}\n",
    "    \n",
    "    # 4.1 Named Entity Recognition (NER)\n",
    "    for ent in doc.ents:\n",
    "        if ent.label_ in [\"PERSON\", \"ORG\"]:\n",
    "            entities[ent.label_].append(ent.text)\n",
    "    \n",
    "    # 4.2 Education keywords\n",
    "    education_keywords = ['btech', 'mtech', 'bachelor', 'master', 'phd', 'computer science', 'engineering', 'degree']\n",
    "    for word in education_keywords:\n",
    "        if word in text.lower():\n",
    "            entities[\"EDUCATION\"].append(word.title())\n",
    "\n",
    "    # 4.3 Skill extraction (custom list)\n",
    "    skills = [\n",
    "        'python', 'java', 'sql', 'c++', 'machine learning', 'deep learning', \n",
    "        'data analysis', 'excel', 'communication', 'leadership', 'html', 'css',\n",
    "        'javascript', 'tensorflow', 'pandas', 'numpy', 'data visualization'\n",
    "    ]\n",
    "    for skill in skills:\n",
    "        if skill in text.lower():\n",
    "            entities[\"SKILLS\"].append(skill.title())\n",
    "\n",
    "    # 4.4 Experience detection\n",
    "    exp_keywords = ['experience', 'worked', 'intern', 'project', 'year']\n",
    "    for word in exp_keywords:\n",
    "        if word in text.lower():\n",
    "            entities[\"EXPERIENCE\"].append(word.title())\n",
    "\n",
    "    # Remove duplicates\n",
    "    for key in entities:\n",
    "        entities[key] = list(set(entities[key]))\n",
    "    \n",
    "    return entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3d460594",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Load and Process Files\n",
    "# ==========================================\n",
    "def read_file(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        return f.read()\n",
    "\n",
    "resume_text = read_file(resume_file)\n",
    "jd_text = read_file(jd_file)\n",
    "\n",
    "clean_resume = clean_text(resume_text)\n",
    "clean_jd = clean_text(jd_text)\n",
    "\n",
    "# Extract information\n",
    "resume_entities = extract_entities(clean_resume)\n",
    "jd_entities = extract_entities(clean_jd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b0a490d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "üìÑ Resume Keywords Extracted\n",
      "==================================================\n",
      "PERSON: ['java mysql', 'matplotlib', 'kibana grafana nprobe', 'kumarey akshatkumareynmimsin']\n",
      "ORG: ['sewa bharati indore hobbies', 'pandas', 'microsoft']\n",
      "EDUCATION: ['Btech', 'Engineering']\n",
      "SKILLS: ['Java', 'Excel', 'Sql', 'Pandas', 'Numpy', 'Machine Learning', 'Python', 'Tensorflow']\n",
      "EXPERIENCE: ['Experience', 'Intern', 'Project']\n",
      "\n",
      "==================================================\n",
      "üíº Job Description Keywords Extracted\n",
      "==================================================\n",
      "PERSON: []\n",
      "ORG: ['mca', 'americas emea']\n",
      "EDUCATION: ['Mtech', 'Computer Science', 'Btech', 'Engineering']\n",
      "SKILLS: ['Java', 'Python']\n",
      "EXPERIENCE: ['Experience', 'Project']\n"
     ]
    }
   ],
   "source": [
    "# üìä Step 6: Display Results\n",
    "# ==========================================\n",
    "def display_output(title, entities):\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(title)\n",
    "    print(\"=\"*50)\n",
    "    for key, values in entities.items():\n",
    "        print(f\"{key}: {values}\")\n",
    "\n",
    "display_output(\"üìÑ Resume Keywords Extracted\", resume_entities)\n",
    "display_output(\"üíº Job Description Keywords Extracted\", jd_entities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0ddfedd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ Common Skills Between Resume and Job Description:\n",
      "['Java', 'Python']\n"
     ]
    }
   ],
   "source": [
    "# üîç Step 7 (Optional): Match Skills Between Resume and Job Description\n",
    "# ==========================================\n",
    "common_skills = set(resume_entities[\"SKILLS\"]) & set(jd_entities[\"SKILLS\"])\n",
    "print(\"\\n‚úÖ Common Skills Between Resume and Job Description:\")\n",
    "print(list(common_skills) if common_skills else \"No common skills found.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
